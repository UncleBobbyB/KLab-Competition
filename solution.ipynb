{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from funs import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "file_path = './train.csv'\n",
    "DF = pd.read_csv(file_path, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()\n",
    "# DF.shape\n",
    "# DF.columns\n",
    "\n",
    "X = DF['review']\n",
    "y = DF['label'] == 'Positive'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing review 0 of 4746.000000\n",
      "Processing review 1000 of 4746.000000\n",
      "Processing review 2000 of 4746.000000\n",
      "Processing review 3000 of 4746.000000\n",
      "Processing review 4000 of 4746.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4746"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning\n",
    "num_reviews = X_train.size\n",
    "clean_train_reviews = []\n",
    "for i in range(num_reviews):\n",
    "    if i % 1000 == 0:\n",
    "        print('Processing review %d of %f' % (i, num_reviews))\n",
    "    clean_train_reviews.append(process_review(X_train.iloc[i]))\n",
    "len(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words\n",
    "vectorizer = CountVectorizer(analyzer='word', max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4746, 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()# 1 * 10000 list\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = np.sum(train_data_features, axis=0)\n",
    "# for tag, count in zip(vocab, dist):\n",
    "#     print(tag, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on random forest\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest = forest.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing AUC\n",
    "num_reviews = X_test.size\n",
    "clean_test_reviews = []\n",
    "for i in range(num_reviews):\n",
    "    clean_test_reviews.append(process_review(X_test.iloc[i]))\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predictions = forest.predict(train_data_features)\n",
    "train_predictions = forest.predict_proba(train_data_features)\n",
    "# test_predictions = forest.predict(test_data_features)\n",
    "test_predictions = forest.predict_proba(test_data_features)\n",
    "# print (test_predictions, test_predictions[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.998, test auc: 0.771\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, train_predictions[:, 1])\n",
    "test_score = roc_auc_score(y_test, test_predictions[:, 1])\n",
    "print ('train auc: %.3f, test auc: %.3f' % (train_score, test_score))\n",
    "# not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Install\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very slow\n",
    "svc = SVC(probability=True)\n",
    "svc.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = svc.predict_proba(train_data_features)\n",
    "train_predictions\n",
    "test_predictions = svc.predict_proba(test_data_features)\n",
    "train_score = roc_auc_score(y_train, train_predictions[:, 1])\n",
    "test_score = roc_auc_score(y_test, test_predictions[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.764, test auc: 0.771\n"
     ]
    }
   ],
   "source": [
    "print ('train auc: %.3f, test auc: %.3f' % (train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
